{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eccc480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test_df =  pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26398594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['label']).values / 255.0 \n",
    "y = train_df['label'].values\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X,y, test_size=0.1, random_state=42)\n",
    "X_train = X_train.T  # Shape (784, 54000)\n",
    "X_dev = X_dev.T      # Shape (784, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ecac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    shifted_Z = Z - np.max(Z, axis=0, keepdims=True)\n",
    "    exp_Z = np.exp(shifted_Z)\n",
    "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "\n",
    "def init_params():\n",
    "    W1 = np.random.randn(128, 784) * np.sqrt(2.0 / 784)\n",
    "    b1 = np.zeros((128, 1))\n",
    "    W2 = np.random.randn(10, 128) * np.sqrt(2.0 / 128)\n",
    "    b2 = np.zeros((10, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return (Z > 0).astype(float)\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_y = np.zeros((Y.size, Y.max()+1))\n",
    "    one_hot_y[np.arange(Y.size), Y] = 1\n",
    "    return one_hot_y.T  \n",
    "\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1 \n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    m = X.shape[1]\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    \n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = (1/m) * dZ2.dot(A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = (1/m) * dZ1.dot(X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, y_true):\n",
    "    return np.mean(predictions == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea80bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, X_dev, y_dev, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    batch_size = 128\n",
    "    m = X_train.shape[1]  # Total samples: 54000\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Mini-Batch Training\n",
    "        permutation = np.random.permutation(m)\n",
    "        X_shuffled = X_train[:, permutation]\n",
    "        y_shuffled = y_train[permutation]\n",
    "        \n",
    "        for start in range(0, m, batch_size):\n",
    "            end = start + batch_size\n",
    "            X_batch = X_shuffled[:, start:end]\n",
    "            y_batch = y_shuffled[start:end]\n",
    "            \n",
    "            # Forward/Backward Pass\n",
    "            Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_batch)\n",
    "            dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X_batch, y_batch)\n",
    "            W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        \n",
    "        # Track Progress\n",
    "        if i % 50 == 0:\n",
    "            train_preds = get_predictions(forward_prop(W1, b1, W2, b2, X_train)[3])\n",
    "            dev_preds = get_predictions(forward_prop(W1, b1, W2, b2, X_dev)[3])\n",
    "            print(f\"Iter {i}: Train Acc={get_accuracy(train_preds, y_train):.3f},Dev Acc={get_accuracy(dev_preds, y_dev):.3f}\")\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Train Acc=0.747,Dev Acc=0.754\n",
      "Iter 50: Train Acc=0.880,Dev Acc=0.872\n",
      "Iter 100: Train Acc=0.898,Dev Acc=0.882\n",
      "Iter 150: Train Acc=0.907,Dev Acc=0.885\n",
      "Iter 200: Train Acc=0.919,Dev Acc=0.886\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(\n",
    "    X_train, y_train,\n",
    "    X_dev, y_dev,\n",
    "    alpha=0.01,  \n",
    "    iterations=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97f62f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m get_accuracy(predictions, y_test)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mtest_df\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      9\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     11\u001b[0m test_model(W1, b1, W2, b2, X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m), y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "def test_model(W1, b1, W2, b2, X_test, y_test):\n",
    "    X_test = X_test.T  # (784, m_test)\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X_test)\n",
    "    predictions = get_predictions(A2)\n",
    "    accuracy = get_accuracy(predictions, y_test)\n",
    "    print(f\"Final Test Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "X_test = test_df.drop(columns=['label']).values / 255.0\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "test_model(W1, b1, W2, b2, X_test.reshape(-1, 784), y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
